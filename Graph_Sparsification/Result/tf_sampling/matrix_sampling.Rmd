---
title: "Matrix sampling"
output: 
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview 
Looking at how sampling rate affect the variances of the matrix. 

The idea is that, the same number of singular values produce the same variance in a sampled matrix as the one in the non-sampled matrix. 

There are 10 matrices, each sampled at different rate [0.1 - 0.9] with three replicates [1-3]. So that's a total of 270 sampled matrices. 

## Import data 
Setting up the required packages and import the data 
```{r libraries, message=FALSE}

library(ggplot2)
library(plyr) # note to self: load this before dplyr always. 
library(dplyr)
library(magrittr)
```

``` {r data}
tf <- read.table("termfreq.summary", header=TRUE)
tf_original <- read.table("tf_original.summary", header = TRUE) 
tfidf <- read.table("tfidf.summary", header=TRUE)
tfidf_original <- read.table("tfidf_original.summary", header=TRUE)
```

## Clean up the data a bit

Just setting some column names.
```{r, message=FALSE}
# Let's separate out the replication and rate  in different columns 
tf <- tf %>% tidyr::separate(matrix_name, c("id", "type", "rate", "replicate"), sep = "_") %>% readr::type_convert()
# Fix column name of tfidf and do the same thing 
tfidf$matrix_name <- gsub(".tfidf", "", tfidf$matrix_name)
tfidf$matrix_name <- gsub("tf", "tfidf", tfidf$matrix_name)
tfidf <- tfidf %>% tidyr::separate(matrix_name, c("id", "type", "rate", "replicate"), sep = "_") %>% readr::type_convert()
```

Combine the data.frames 
```{r}
# Add the original matrix into the tf data.frame 
tf_original$replicate = "1"
tf_original$rate = 1
tf_original <- tf_original %>% tidyr::separate(matrix_name, c("id", "type"), sep = "[.]")
tf <- rbind(tf, tf_original)

# Add the original to the tfidf data.frame 
tfidf_original$replicate = "1"
tfidf_original$rate = 1
tfidf_original <- tfidf_original %>% tidyr::separate(matrix_name, c("id", "type"), sep = "[.]")
tfidf <- rbind(tfidf, tfidf_original)

```
Fix up the types of the columns 
```{r}
# combine the two
all <- rbind(tf, tfidf)

# Turn nsv into factor 
all$nsv <- as.factor(all$nsv)
all$id <- as.factor(all$id)
all$type <- as.factor(all$type)
```

What the data look like
```{r}
head(all)
str(all)
```

## Analyzing data

For each grouping of id-rate-nsv, calculate the mean variance and the standard devi

```{r}
tfidf_summary <- all[all$type=="tfidf", ] %>% dplyr::group_by(id, rate, nsv) %>% dplyr::summarise_at(c("variance", "forbenius"), c("mean", "sd")) %>% dplyr::mutate(cov = variance_mean / forbenius_mean)
tf_summary <- all[all$type=="tf", ] %>% dplyr::group_by(id, rate, nsv) %>% dplyr::summarise_at(c("variance", "forbenius"), c("mean", "sd")) %>% dplyr::mutate(cov = variance_mean / forbenius_mean)
```

```{r}
head(tf_summary)
```

## Result

Excluding id 9 to make the facet-wrap 3 by 3. Don't worry, it's not an outlier. 
```{r}
tf_summary <- tf_summary[tf_summary$id != "9",]
tfidf_summary <- tfidf_summary[tfidf_summary$id != "9",]
```


```{r tf_coverage}
# Plot the one for tf 
ggplot(tf_summary, aes(x = rate, y = cov, colour = nsv, group = nsv)) + geom_point() + geom_line() + facet_wrap(~id)
```
From this plot we can see that lower sampling rate result in smaller coverage, which is measured by taking the ratio of the variance (of given number of singular values) and forbenius norm. The lines are relatively flat and this is consistent across different matrices. This means we could sample the matrix and the same number of singular values would still be representative enough compare to a matrix that's not sampled. 

```{r tf_tfidf_coverage}
# Plot tfidf 
ggplot(tfidf_summary, aes(x = rate, y = cov, colour = nsv, group = nsv)) + geom_point() + geom_line() + facet_wrap(~id)
```

After some thoughts, I realize that sampling the matrix by taking a subset of the word occurences using a probability rate AND THEN convert the result into TFIDF doesn't really make sense. 

TFIDF(occurrences, term) = (1 + log(occurrences)) * log(nDoc/(nDoc with the term))

Just looking at the first term  TF = 1 + log(occurrences).  1+log(x) where x is an integer 1,2,3..., we can calculate that the change of TF is not constant as X increase.  So I'm not sure if sampling occurrences and then converting the result to TFIDF make sense.  

Therefore, I'll try sampling AFTER converting to TFIDF next time. 

From the look of the graph though, the curves are quite flat and sampling seems to be able to give us a good idea of coverage. 


## Running time

We should sanity-check whether sampling reduces running time and that correlates to less entries in the matrix (next).

Note that we do not include the run time and the sparsity information of non-sampled matrices because SVD for those matrices were run separately, possibly on different machines, so we cannot compare their SVD run time with the sampled matrices. 

Load data
```{r}
run_time <- read.table("termfreq_runningtime.result", header=TRUE)
run_time$matrix_name <- factor(run_time$matrix_name)
```

Summarize the data by taking the average

```{r}
get_summary <- function(data) {
  summary <- data %>% dplyr::group_by(matrix_name, sample_rate) %>% dplyr::summarise_at(c("run_time"), c("mean", "sd")) %>% dplyr::mutate(de = sd/sqrt(3) )
}
run_time_summary <- get_summary(run_time)
head(run_time_summary)
```

Graph result 

```{r runningtime_tfidf_summary}
ggplot(run_time_summary, aes(x = sample_rate, y = mean)) + geom_point() + geom_line() + geom_errorbar(aes(ymax = mean + de, ymin=mean - de), width=0.01) +  facet_wrap(~matrix_name)
```

Make 3 by 3 
```{r runningtime_tfidf_3by3}
ggplot(run_time_summary[run_time_summary$matrix_name!="98", ], aes(x = sample_rate, y = mean)) + geom_point() + geom_line() + geom_errorbar(aes(ymax = mean + de, ymin=mean - de), width=0.01) +  facet_wrap(~matrix_name)
```

Combine all matrices

```{r runningtime_tfidf_all_matrices}
ggplot(run_time_summary[run_time_summary$matrix_name!="98", ], aes(x = sample_rate, y = mean)) + geom_point() + stat_summary(fun.y = mean, geom="line", size=1.0)
```


## Sparsity 

Load data
```{r}
sparsity <- read.table("sparsity_tf.result", header=TRUE)
str(sparsity)
sparsity$matrix_name <- factor(sparsity$matrix_name)
```

Summarize the data by taking the average

```{r}
get_summary <- function(data) {
  summary <- data %>% dplyr::group_by(matrix_name, sample_rate) %>% dplyr::summarise_at(c("n_entries"), c("mean", "sd")) %>% dplyr::mutate(de = sd/sqrt(3) )
}
sparsity_summary <- get_summary(sparsity)
head(sparsity_summary)
```

Graph result 

```{r sparsity_tfidf_summary}
ggplot(sparsity_summary, aes(x = sample_rate, y = mean)) + geom_point() + geom_line() + geom_errorbar(aes(ymax = mean + de, ymin=mean - de), width=0.01) +  facet_wrap(~matrix_name)
```

Make 3 by 3 
```{r sparsity_tfidf_3by3}
ggplot(sparsity_summary[sparsity_summary$matrix_name!="9", ], aes(x = sample_rate, y = mean)) + geom_point() + geom_line() + geom_errorbar(aes(ymax = mean + de, ymin=mean - de), width=0.01) +  facet_wrap(~matrix_name)
```

Sampling is fairly consistent at producing matrices with the same sparsity. 

Combine different matrices together 
```{r sparsity_tfidf_allmatrices}
ggplot(sparsity_summary, aes(x = sample_rate, y = mean)) + geom_point() + geom_errorbar(aes(ymax = mean + de, ymin=mean - de), width=0.01) + stat_summary(fun.y = mean, geom="line", size=1.0)
```